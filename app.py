from flask import Flask, send_from_directory, render_template, request, jsonify, Response
import google.generativeai as genai
from nltk.tokenize import sent_tokenize
from flask_cors import CORS
import json
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import re
import os

app = Flask(__name__, static_folder="static")
CORS(app)

# ğŸ”¹ Google Gemini API ì„¤ì •
genai.configure(api_key="AIzaSyCptpJ68R5lyJPduY8rtqUXR9Ij7F4puoE")

with open('data.txt', 'r', encoding='utf-8') as file:
    text = file.read()

def split_text_into_chunks(text, chunk_size=1000, overlap=200):
    words = text.split()
    chunks = []
    start = 0
    while start < len(words):
        end = start + chunk_size
        chunks.append(' '.join(words[start:end]))
        start += (chunk_size - overlap)
    return chunks

document_sentences = split_text_into_chunks(text)

def preprocess(text):
    return ' '.join(text.split())

def find_most_similar_sentences(user_question, document_sentences, top_n=10):
    sentences = [preprocess(sentence) for sentence in document_sentences]
    vectorizer = TfidfVectorizer().fit_transform([user_question] + sentences)
    cosine_matrix = cosine_similarity(vectorizer[0:1], vectorizer[1:])
    similar_sentences = np.argsort(cosine_matrix[0])[-top_n:][::-1]
    return [sentences[i] for i in similar_sentences]

def convert_urls_to_links(text):
    url_pattern = re.compile(r'(http[s]?://\S+)')
    return url_pattern.sub(r'<a href="\1" target="_blank">\1</a>', text)

@app.route('/static/<path:filename>')
def serve_static(filename):
    return send_from_directory(app.static_folder, filename)

@app.route("/")
def index():
    return render_template('./index.html')

GEMINI_MODELS = [
    "gemini-2.0-flash",                    # 1ï¸âƒ£ Gemini 2.0 Flash
    "gemini-2.0-flash-lite-preview",        # 2ï¸âƒ£ Gemini 2.0 Flash-Lite ë¯¸ë¦¬ë³´ê¸°
    "gemini-1.5-flash",                     # 3ï¸âƒ£ Gemini 1.5 Flash
    "gemini-1.5-flash-8b",                  # 4ï¸âƒ£ Gemini 1.5 Flash-8B
    "gemini-2.0-pro-experimental-02-05",    # 5ï¸âƒ£ Gemini 2.0 Pro Experimental
    "gemini-1.5-pro"                        # 6ï¸âƒ£ Gemini 1.5 Pro
]

@app.route('/chat', methods=['POST'])
def chat():
    data = request.get_json()
    user_question = data.get('question') + "?"
    relevant_text = find_most_similar_sentences(user_question, document_sentences, top_n=10)

    # ğŸ”¹ AIì—ê²Œ ì „ë‹¬í•  ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
    system_message = f"""{relevant_text}

    ë‹¹ì‹ ì€ í•™êµí–‰ì •ì—…ë¬´ ì„œí¬í„°ì…ë‹ˆë‹¤. 
    1. ì•ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìµœëŒ€ 7ë¬¸ì¥ ì´ë‚´+70ë‹¨ì–´ ì´ë‚´ë¡œ ìš”ì•½í•´ì„œ ì¡´ëŒ“ë§ë¡œ ë‹µí•´ì¤˜. 
    2. ì§ˆë¬¸ì´ ë‚´ìš©ê³¼ ê´€ê³„ì—†ìœ¼ë©´ ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì‹œê² ì–´ìš”? ë¼ê³  ë‹µë³€í•´ì¤˜. 
    3. ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œë§Œ ë‹µí•´ì¤˜. ë˜í•œ ì˜ˆì™¸ ì‚¬í•­ì´ë‚˜ ì‚¬ë¡€ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒë„ ë‹µí•´ì¤˜. 
    4. ì‚¬ìš©ìì—ê²Œ ì¬ì§ˆë¬¸ ê¸ˆì§€. 
    5. ê´€ë ¨ ë²•ë ¹ë„ ê°™ì´ ë‹µë³€(ë‹µë³€ì‹œ ì°¸ì¡°í•œ ë¬¸ì¥ê³¼ ì •í™•íˆ ê´€ë ¨ëœ ë²•ë ¹). 
    6. ë§í¬ê°€ ìˆìœ¼ë©´ ë§í¬ë„ ë‹µë³€(ë‹µë³€ê³¼ ê´€ë ¨ìˆëŠ” ë§í¬ë§Œ)."""
    response = None
    last_exception = None  # ğŸ”¹ ë§ˆì§€ë§‰ ì˜¤ë¥˜ ì €ì¥
    switched_model = None  # ğŸ”¹ ì‚¬ìš©ëœ ëª¨ë¸ ì €ì¥

    for model in GEMINI_MODELS:
        try:
            print(f"[ğŸ”„] ëª¨ë¸ ì‹œë„: {model}")  # ğŸ”¹ ë¡œê·¸ì—ëŠ” ëª¨ë¸ ë³€ê²½ ë‚´ì—­ í‘œì‹œ
            client = genai.GenerativeModel(model)
            response = client.generate_content(user_question)
            
            if response and hasattr(response, 'text') and response.text:
                print(f"[âœ…] ëª¨ë¸ {model} ì‚¬ìš© ì„±ê³µ!")
                switched_model = model  # ğŸ”¹ ëª¨ë¸ ë³€ê²½ ê°ì§€
                break

        except Exception as e:
            error_message = str(e).lower()
            last_exception = e  # ğŸ”¹ ë§ˆì§€ë§‰ ì˜¤ë¥˜ ì €ì¥
            
            if "quota exceeded" in error_message or "rate limit" in error_message or "429" in error_message:
                print(f"[âš ï¸] {model} í•œë„ ì´ˆê³¼! ë‹¤ìŒ ëª¨ë¸ë¡œ ì „í™˜ ì¤‘...")
                continue  # ë‹¤ìŒ ëª¨ë¸ ì‹œë„
            
            print(f"[âŒ] {model} í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return jsonify({"answer": f"AI ì‘ë‹µ ì˜¤ë¥˜: {str(e)}"})

    if response is None or not hasattr(response, 'text') or not response.text:
        print("[âŒ] ëª¨ë“  ëª¨ë¸ì´ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
        return jsonify({"answer": f"í˜„ì¬ ëª¨ë“  AI ëª¨ë¸ì´ ì‚¬ìš© ë¶ˆê°€ ìƒíƒœì…ë‹ˆë‹¤. (ì—ëŸ¬: {last_exception})"})

    # ğŸ”¹ ì‚¬ìš©ëœ ëª¨ë¸ ì •ë³´ë¥¼ ë¡œê·¸ì—ëŠ” ë‚¨ê¸°ì§€ë§Œ, ì‹¤ì œ ì‘ë‹µì—ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ
    if switched_model:
        print(f"[â„¹ï¸] ìµœì¢… ì‚¬ìš©ëœ ëª¨ë¸: {switched_model}")

    response_data = {"answer": response.text}  # ğŸ”¥ ì‚¬ì´íŠ¸ ëŒ€í™”ì—ì„œëŠ” ëª¨ë¸ ë³€ê²½ ë©”ì‹œì§€ ì œê±°

    return app.response_class(
        response=json.dumps(response_data, ensure_ascii=False),  # âœ¨ í•œê¸€ ê¹¨ì§ ë°©ì§€
        status=200,
        mimetype="application/json"
    )

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
